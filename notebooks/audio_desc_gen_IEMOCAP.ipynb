{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 16:36:21.634649: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-13 16:36:21.642421: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-13 16:36:21.651569: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-13 16:36:21.654330: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-13 16:36:21.661448: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-13 16:36:22.180489: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re \n",
    "import json\n",
    "import warnings\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from io import BytesIO\n",
    "from pydub import AudioSegment\n",
    "from urllib.request import urlopen\n",
    "from transformers import Qwen2AudioForConditionalGeneration, AutoProcessor\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/shareds/IEMOCAP/IEMOCAP_full_release/'\n",
    "save_path = '/shareds/IEMOCAP/IEMOCAP_audio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion2short = {'Neutral': 'neu', \n",
    "                 'Excited': 'exc', \n",
    "                 'Frustration': 'fru', \n",
    "                 'Sadness': 'sad', \n",
    "                 'Anger': 'ang', \n",
    "                 'Happiness': 'hap' \n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotion(label):\n",
    "    emotions = dict()\n",
    "    for row in ''.join(label).split('\\n\\n')[1:-1]:\n",
    "        row = row.split('\\n')\n",
    "        head = row[0].split('\\t')\n",
    "        name = head[1]\n",
    "        emo = head[2]\n",
    "        if emo not in list(emotion2short.values()):\n",
    "            answers = ''\n",
    "            for e in row[1:]:\n",
    "                if e[0] == 'C':\n",
    "                    answers += e.split('\\t')[1] + ' '\n",
    "            answers = answers.split('; ')\n",
    "            answers = [e for e in answers if e in emotion2short]\n",
    "            if answers:\n",
    "                emo = emotion2short[max(set(answers), key=answers.count)]\n",
    "            else:\n",
    "                emo = np.nan\n",
    "        emotions[name] = emo\n",
    "    return emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [00:36<00:00,  7.36s/it]\n"
     ]
    }
   ],
   "source": [
    "label_pattern = r'^(\\S+)\\s+\\[([0-9]+\\.[0-9]+)-([0-9]+\\.[0-9]+)\\]:\\s*(.*)$'\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "markup = pd.DataFrame(columns=['session', 'fn', 'idx', 'sex', 'emotion', 'text'])\n",
    "for i in tqdm(range(1, 6)):\n",
    "    os.makedirs(f'{save_path}/Session{i}', exist_ok=True)\n",
    "    for fn in os.listdir(f'{data_path}Session{i}/dialog/transcriptions/'):\n",
    "        if fn[0] == '.':\n",
    "            continue\n",
    "        os.makedirs(f'{save_path}/Session{i}/{fn[:-4]}', exist_ok=True)\n",
    "        \n",
    "        with open(f'{data_path}/Session{i}/dialog/transcriptions/{fn}', 'r') as f:\n",
    "            labels = f.readlines()\n",
    "\n",
    "        with open(f'{data_path}/Session{i}/dialog/EmoEvaluation/{fn}', 'r') as f:\n",
    "            emotions = f.readlines()\n",
    "            emotions = get_emotion(emotions)\n",
    "            \n",
    "        for j, label in enumerate(labels):\n",
    "            match = re.match(label_pattern, label)\n",
    "            if match is None:\n",
    "                # print(f\"Invalid label: {label}\")\n",
    "                continue\n",
    "            row_name, start_time, end_time, text = [match.group(i) for i in range(1, 5)]\n",
    "\n",
    "            audio_path = f'{data_path}/Session{i}/dialog/wav/{fn[:-4]}.wav'\n",
    "            if not os.path.isfile(audio_path):\n",
    "                print(f\"No such file or directory: {audio_path}\")\n",
    "                continue\n",
    "                \n",
    "            start_sec = float(start_time) + 2 / 100\n",
    "            end_sec = float(end_time) + 2 / 100\n",
    "        \n",
    "            audio = AudioSegment.from_wav(audio_path)\n",
    "        \n",
    "            start_ms = int(start_sec * 1000)\n",
    "            end_ms = int(end_sec * 1000)\n",
    "        \n",
    "            clip = audio[start_ms:end_ms]\n",
    "            audio_save_path = f'{save_path}/Session{i}/{fn[:-4]}/{j}.wav'\n",
    "            if label.split(' ')[0] in emotions:\n",
    "                clip.export(audio_save_path, format=\"wav\")\n",
    "                markup.loc[markup.shape[0]] = [i, fn[:-4], j, row_name[-4], emotions[label.split(' ')[0]], text]\n",
    "markup = markup.dropna()\n",
    "markup.to_csv(f'{save_path}/markup.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ef60baa2f54f92a54f58ffad278659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-Audio-7B-Instruct\")\n",
    "model = Qwen2AudioForConditionalGeneration.from_pretrained(\"Qwen/Qwen2-Audio-7B-Instruct\", device_map=\"auto\", load_in_4bit=True)\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>fn</th>\n",
       "      <th>idx</th>\n",
       "      <th>sex</th>\n",
       "      <th>emotion</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Ses01F_impro07</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>exc</td>\n",
       "      <td>Did you get the letter?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ses01F_impro07</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>exc</td>\n",
       "      <td>Yes.  There's a big envelope it says, you're i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Ses01F_impro07</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>exc</td>\n",
       "      <td>Yeah. That is so awesome.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Ses01F_impro07</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>exc</td>\n",
       "      <td>Oh my God. What are you going to do? [LAUGHTER]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Ses01F_impro07</td>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>exc</td>\n",
       "      <td>So I have to move back to the ghetto but...I k...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session              fn  idx sex emotion  \\\n",
       "0        1  Ses01F_impro07    0   M     exc   \n",
       "1        1  Ses01F_impro07    1   F     exc   \n",
       "2        1  Ses01F_impro07    2   M     exc   \n",
       "3        1  Ses01F_impro07    4   M     exc   \n",
       "4        1  Ses01F_impro07    5   F     exc   \n",
       "\n",
       "                                                text  \n",
       "0                            Did you get the letter?  \n",
       "1  Yes.  There's a big envelope it says, you're i...  \n",
       "2                          Yeah. That is so awesome.  \n",
       "3    Oh my God. What are you going to do? [LAUGHTER]  \n",
       "4  So I have to move back to the ghetto but...I k...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(f'{save_path}/markup.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1255 [00:00<?, ?it/s]The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "100%|█████████████████████████████████████| 1255/1255 [5:31:55<00:00, 15.87s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "max_new_tokens = 256    \n",
    "audio_desc = [\"Nan\"] * len(data)  \n",
    "\n",
    "num_rows = len(data)\n",
    "for start_idx in tqdm(range(0, num_rows, batch_size)):\n",
    "    end_idx = min(start_idx + batch_size, num_rows)\n",
    "    batch = data.iloc[start_idx:end_idx]\n",
    "\n",
    "    all_texts = []\n",
    "    all_audios = []\n",
    "    valid_indices = []  \n",
    "\n",
    "    for i, row in batch.iterrows():\n",
    "        sess, file, local_idx, sex, emotion, _ = row\n",
    "        audio_path = f\"{save_path}/Session{sess}/{file}/{local_idx}.wav\"\n",
    "\n",
    "        conversation = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"You are a helpful assistant that provides a thorough analysis of the speaker’s voice. \"\n",
    "                    \"Focus on describing their tone, intonation, pitch, volume, pace, emotional nuances, \"\n",
    "                    \"and any distinguishing characteristics. Provide a detailed multi-sentence description \"\n",
    "                    \"rather than a single-word or single-sentence answer. Avoid guessing personal data like \"\n",
    "                    \"name or exact age, and focus instead on audible cues and impressions from the voice.\"\n",
    "                )\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"audio\",\n",
    "                        \"audio_url\": \"file://\" + audio_path\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": (\n",
    "                            \"Please describe in detail what the speaker’s voice sounds like. \"\n",
    "                            \"Comment on pitch, speed, intonation, emotional tone, and any other notable traits. \"\n",
    "                            \"Use at least three sentences.\"\n",
    "                        )\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        text = processor.apply_chat_template(\n",
    "            conversation,\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=False\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            au, sr = librosa.load(\n",
    "                audio_path,\n",
    "                sr=processor.feature_extractor.sampling_rate\n",
    "            )\n",
    "            all_texts.append(text)\n",
    "            all_audios.append(au)\n",
    "            valid_indices.append(i) \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {audio_path}: {e}\")\n",
    "            # data.at[i, \"audio_caption\"] = \"Nan\"\n",
    "\n",
    "    if not valid_indices:\n",
    "        continue\n",
    "\n",
    "    inputs = processor(\n",
    "        text=all_texts,\n",
    "        audios=all_audios,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        sampling_rate=processor.feature_extractor.sampling_rate\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generate_ids = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "\n",
    "    prompt_length = inputs.input_ids.shape[1]\n",
    "\n",
    "    generate_ids = generate_ids[:, prompt_length:]\n",
    "\n",
    "    responses = processor.batch_decode(\n",
    "        generate_ids,\n",
    "        skip_special_tokens=True,\n",
    "        clean_up_tokenization_spaces=False\n",
    "    )\n",
    "\n",
    "    for idx_local, resp in zip(valid_indices, responses):\n",
    "        audio_desc[idx_local] = resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>fn</th>\n",
       "      <th>idx</th>\n",
       "      <th>sex</th>\n",
       "      <th>emotion</th>\n",
       "      <th>text</th>\n",
       "      <th>audio_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Ses01F_impro07</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>exc</td>\n",
       "      <td>Did you get the letter?</td>\n",
       "      <td>The speaker's voice is that of an English male...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ses01F_impro07</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>exc</td>\n",
       "      <td>Yes.  There's a big envelope it says, you're i...</td>\n",
       "      <td>The speaker's voice is high-pitched with a you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Ses01F_impro07</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>exc</td>\n",
       "      <td>Yeah. That is so awesome.</td>\n",
       "      <td>The speaker's voice has a bright quality with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Ses01F_impro07</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>exc</td>\n",
       "      <td>Oh my God. What are you going to do? [LAUGHTER]</td>\n",
       "      <td>The speaker's voice has a light and airy quali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Ses01F_impro07</td>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>exc</td>\n",
       "      <td>So I have to move back to the ghetto but...I k...</td>\n",
       "      <td>The speaker's voice has a light and airy quali...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session              fn  idx sex emotion  \\\n",
       "0        1  Ses01F_impro07    0   M     exc   \n",
       "1        1  Ses01F_impro07    1   F     exc   \n",
       "2        1  Ses01F_impro07    2   M     exc   \n",
       "3        1  Ses01F_impro07    4   M     exc   \n",
       "4        1  Ses01F_impro07    5   F     exc   \n",
       "\n",
       "                                                text  \\\n",
       "0                            Did you get the letter?   \n",
       "1  Yes.  There's a big envelope it says, you're i...   \n",
       "2                          Yeah. That is so awesome.   \n",
       "3    Oh my God. What are you going to do? [LAUGHTER]   \n",
       "4  So I have to move back to the ghetto but...I k...   \n",
       "\n",
       "                                       audio_caption  \n",
       "0  The speaker's voice is that of an English male...  \n",
       "1  The speaker's voice is high-pitched with a you...  \n",
       "2  The speaker's voice has a bright quality with ...  \n",
       "3  The speaker's voice has a light and airy quali...  \n",
       "4  The speaker's voice has a light and airy quali...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['audio_caption'] = audio_desc\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"../data/IEMOCAP/modified_data1303.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
